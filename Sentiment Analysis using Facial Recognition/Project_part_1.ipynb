{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project part 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q Kaggle"
      ],
      "metadata": {
        "id": "9J7TQxyfNouD"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "8ysKJ1gtN15o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/content/kaggle.json\" ~/.kaggle"
      ],
      "metadata": {
        "id": "aPebgJ15N2A2"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "4BmFEcKFOQuJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d aadityasinghal/facial-expression-dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1P9K4hcObh1",
        "outputId": "dc49ed01-1c1f-4257-b342-fb3fe1eb6dca"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading facial-expression-dataset.zip to /content\n",
            " 68% 41.0M/60.7M [00:00<00:00, 31.2MB/s]\n",
            "100% 60.7M/60.7M [00:01<00:00, 59.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/facial-expression-dataset.zip"
      ],
      "metadata": {
        "id": "ivzhPXr0PZ4C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install livelossplot==0.5.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0cUzQBgrMI_f",
        "outputId": "ce6a22e3-5f46-40c9-ef19-c17d8318561d"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: livelossplot==0.5.2 in /usr/local/lib/python3.7/dist-packages (0.5.2)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.2) (2.3.3)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.2) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot==0.5.2) (3.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.2) (2.8.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.2) (21.3)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.2) (5.1.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.2) (1.19.5)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.2) (7.1.2)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.2) (3.13)\n",
            "Requirement already satisfied: Jinja2>=2.9 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.2) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot==0.5.2) (3.10.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.9->bokeh->livelossplot==0.5.2) (2.0.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=16.8->bokeh->livelossplot==0.5.2) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot==0.5.2) (1.15.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.2) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.2) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.2) (0.7.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.2) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.2) (2.6.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.2) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.2) (5.1.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot==0.5.2) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot==0.5.2) (0.2.5)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.5.2) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot==0.5.2) (0.11.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->livelossplot==0.5.2) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install python-utils"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5J4tamUuX0W",
        "outputId": "8a29da8f-c06c-4247-ab71-01c0aad0e83f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: python-utils in /usr/local/lib/python3.7/dist-packages (2.5.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from python-utils) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rIvkb4bpKsbh",
        "outputId": "afd27120-d545-4a12-d128-c39283371568"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version: 2.7.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import python_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout,Flatten, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from IPython.display import SVG, Image\n",
        "import tensorflow as tf\n",
        "from livelossplot.inputs.tf_keras import PlotLossesCallback\n",
        "print(\"Tensorflow version:\", tf.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 48\n",
        "batch_size = 64\n",
        "datagen_train = ImageDataGenerator(horizontal_flip=True)\n",
        "train_generator = datagen_train.flow_from_directory(\"/content/test/test\",\n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n",
        "datagen_validation = ImageDataGenerator(horizontal_flip=True)\n",
        "validation_generator = datagen_validation.flow_from_directory(\"/content/train/train\",\n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    color_mode=\"grayscale\",\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=False)"
      ],
      "metadata": {
        "id": "bP2D3CLhI0SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "218c742a-fb55-4250-e45a-20accc8b412d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 7178 images belonging to 7 classes.\n",
            "Found 28709 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising the CNN\n",
        "model = Sequential()\n",
        "# 1 - Convolution\n",
        "model.add(Conv2D(64,(3,3), padding='same', input_shape=(48, 48,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "# 2nd Convolution layer\n",
        "model.add(Conv2D(128,(5,5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "# 3rd Convolution layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "# 4th Convolution layer\n",
        "model.add(Conv2D(512,(3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "# Flattening\n",
        "model.add(Flatten())\n",
        "# Fully connected layer 1st layer\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "# Fully connected layer 2nd layer\n",
        "model.add(Dense(512))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "opt = Adam(lr=0.0005)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L5jrjdXVJMX_",
        "outputId": "3509d66f-de81-43e0-bd18-adc638c792e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 48, 48, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 48, 48, 64)       256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 48, 48, 64)        0         \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 24, 24, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 24, 24, 128)       204928    \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 24, 128)      512       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 24, 128)       0         \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 12, 12, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 12, 12, 512)       590336    \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 12, 12, 512)      2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 12, 12, 512)       0         \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 6, 6, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 6, 6, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_3 (Batc  (None, 6, 6, 512)        2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_3 (Activation)   (None, 6, 6, 512)         0         \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 3, 3, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 3, 3, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 4608)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1179904   \n",
            "                                                                 \n",
            " batch_normalization_4 (Batc  (None, 256)              1024      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_4 (Activation)   (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               131584    \n",
            "                                                                 \n",
            " batch_normalization_5 (Batc  (None, 512)              2048      \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_5 (Activation)   (None, 512)               0         \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,478,727\n",
            "Trainable params: 4,474,759\n",
            "Non-trainable params: 3,968\n",
            "_________________________________________________________________\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "epochs = 1\n",
        "steps_per_epoch = train_generator.n//train_generator.batch_size\n",
        "validation_steps = validation_generator.n//validation_generator.batch_size\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1,\n",
        "                              patience=2, min_lr=0.00001, mode='auto')\n",
        "checkpoint = ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy',\n",
        "                             save_weights_only=True, mode='max', verbose=1)\n",
        "callbacks = [PlotLossesCallback(), checkpoint, reduce_lr]\n",
        "history = model.fit(\n",
        "    x=train_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    epochs=epochs,\n",
        "    validation_data = validation_generator,\n",
        "    validation_steps = validation_steps,\n",
        "    callbacks=[checkpoint]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zG6YNJt3JcOq",
        "outputId": "c80ee03f-f691-47b2-ff95-1421b56ea546"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - ETA: 0s - loss: 1.8319 - accuracy: 0.2880\n",
            "Epoch 00001: saving model to model_weights.h5\n",
            "112/112 [==============================] - 620s 6s/step - loss: 1.8319 - accuracy: 0.2880 - val_loss: 1.7709 - val_accuracy: 0.3198\n",
            "CPU times: user 19min 46s, sys: 10.7 s, total: 19min 57s\n",
            "Wall time: 10min 21s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "model.save_weights('model_weights.h5')\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)"
      ],
      "metadata": {
        "id": "145s51ClJlw9"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import model_from_json\n",
        "class FacialExpressionModel(object):\n",
        "    EMOTIONS_LIST = [\"Angry\", \"Disgust\",\n",
        "                    \"Fear\", \"Happy\",\n",
        "                    \"Neutral\", \"Sad\",\n",
        "                    \"Surprise\"]\n",
        "    def __init__(self, model_json_file, model_weights_file):\n",
        "        # load model from JSON file\n",
        "        with open(model_json_file, \"r\") as json_file:\n",
        "            loaded_model_json = json_file.read()\n",
        "            self.loaded_model = model_from_json(loaded_model_json)\n",
        "        # load weights into the new model\n",
        "        self.loaded_model.load_weights(model_weights_file)\n",
        "        self.loaded_model.make_predict_function()\n",
        "    def predict_emotion(self, img):\n",
        "        self.preds = self.loaded_model.predict(img)\n",
        "        return FacialExpressionModel.EMOTIONS_LIST[np.argmax(self.preds)]"
      ],
      "metadata": {
        "id": "8SKkZe1NJ1fu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "facec = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
        "model = FacialExpressionModel(\"model.json\", \"model_weights.h5\")\n",
        "font = cv2.FONT_HERSHEY_SIMPLEX\n",
        "class VideoCamera(object):\n",
        "    def __init__(self):\n",
        "        self.video = cv2.VideoCapture(0)\n",
        "    def __del__(self):\n",
        "        self.video.release()\n",
        "    # returns camera frames along with bounding boxes and predictions\n",
        "    def get_frame(self):\n",
        "        _, fr = self.video.read()\n",
        "        gray_fr = cv2.cvtColor(fr, cv2.COLOR_BGR2GRAY)\n",
        "        faces = facec.detectMultiScale(gray_fr, 1.3, 5)\n",
        "        for (x, y, w, h) in faces:\n",
        "            fc = gray_fr[y:y+h, x:x+w]\n",
        "            roi = cv2.resize(fc, (48, 48))\n",
        "            pred = model.predict_emotion(roi[np.newaxis, :, :, np.newaxis])\n",
        "            cv2.putText(fr, pred, (x, y), font, 1, (255, 255, 0), 2)\n",
        "            cv2.rectangle(fr,(x,y),(x+w,y+h),(255,0,0),2)\n",
        "        return fr"
      ],
      "metadata": {
        "id": "WNF9dsaiJ3OZ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gen(camera):\n",
        "    while True:\n",
        "        frame = camera.get_frame()\n",
        "        cv2.imshow('Facial Expression Recognization',frame)\n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "oGhyVq-pJ-T3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cv2.VideoCapture(0)"
      ],
      "metadata": {
        "id": "p1q-nVGqKINK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a2178cd-d5f3-4239-eee4-dfdbd49992d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<VideoCapture 0x7f2e24da7790>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from google.colab.patches import cv2_imshow\n",
        "cap = cv2.VideoCapture(0)\n",
        "(rval, im) = cap.read()\n",
        "cv2.imshow('LIVE',   im)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "KFhB0uUq44hf",
        "outputId": "83dec02b-2335-494e-ae12-6cbe70c79dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "DisabledFunctionError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDisabledFunctionError\u001b[0m                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-ad32dab9423e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVideoCapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LIVE'\u001b[0m\u001b[0;34m,\u001b[0m   \u001b[0mim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/google/colab/_import_hooks/_cv2.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mDisabledFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDisabledFunctionError\u001b[0m: cv2.imshow() is disabled in Colab, because it causes Jupyter sessions\nto crash; see https://github.com/jupyter/notebook/issues/3935.\nAs a substitution, consider using\n  from google.colab.patches import cv2_imshow\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_snippet",
                "actionText": "Search Snippets for cv2.imshow",
                "snippetFilter": "cv2.imshow"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Qsqdyrh-6UbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}